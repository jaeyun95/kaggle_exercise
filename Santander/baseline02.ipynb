{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline02.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9qzMSsb_xQL"
      },
      "source": [
        "use_dates = [\"2016-01-28\",\"2016-02-28\",\"2016-03-28\",\"2016-04-28\",\"2016-05-28\"]\n",
        "\n",
        "trn = df_trn[df_trn[\"fecha_dato\"].isin(use_dates)]\n",
        "tst = df_trn[df_trn[\"fecha_dato\"] == \"2016-06-28\"]\n",
        "\n",
        "del df_trn\n",
        "\n",
        "X, Y = [], []\n",
        "\n",
        "for i, prod in enumerate(prods):\n",
        "  prev = prod + \"_prev\"\n",
        "  prX = trn[(trn[prod]==1)&(trn[prod]==0)]\n",
        "  prY = np.zeros(prX.shape[0],dtype=np.int8) + i\n",
        "  X.append(prX)\n",
        "  Y.append(prY)\n",
        "\n",
        "XY = pd.concat(X)\n",
        "Y = np.hstack(Y)\n",
        "XY['y'] = Y\n",
        "\n",
        "vld_date = \"2016-05-28\"\n",
        "XY_trn = XY[XY['fecha_dato'] != vld_date]\n",
        "XY_vld = XY[XY['fecha_dato'] == vld_date]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Thh8Ns_xyV"
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "param = {\n",
        "    \"booster\":\"gbtree\",\n",
        "    \"max_depth\":8,\n",
        "    \"nthread\":4,\n",
        "    \"num_class\":len(prods),\n",
        "    \"objective\":\"multi:softprob\",\n",
        "    \"silent\":1,\n",
        "    \"eval_metric\":\"mlogloss\",\n",
        "    \"eta\":0.1,\n",
        "    \"min_child_weight\":10,\n",
        "    \"colsample_bytree\":0.8,\n",
        "    \"colsample_bylevel\":0.9,\n",
        "    \"seed\":2021,\n",
        "}\n",
        "\n",
        "# mapk\n",
        "def apk(actual, predicted, k=7, default=0.0):\n",
        "  if len(predicted) > k:\n",
        "    predicted = predicted[:k]\n",
        "\n",
        "  score = 0.0\n",
        "  num_hits = 0.0\n",
        "\n",
        "  for i,p in enumerate(predicted):\n",
        "    if p in actual and p not in predicted[:i]:\n",
        "      num_hits += 1.0\n",
        "      score += num_hits/(i+1.0)\n",
        "\n",
        "  if not actual:\n",
        "    return default\n",
        "\n",
        "  return score / min(len(actual),k)\n",
        "\n",
        "def mapk(actual, predicted, k=7, default=0.0):\n",
        "  return np.mean([apk(a,p,k,default) for a,p in zip(actual,predicted)])\n",
        "\n",
        "# XGBoost 형태에 맞게 데이터 변형\n",
        "X_trn = XY_trn.as_matrix(columns=features)\n",
        "Y_trn = XY_trn.as_matrix(columns=['y'])\n",
        "dtrn = xgb.DMatrix(X_trn, label=Y_trn, feature_names=features)\n",
        "\n",
        "X_vld = XY_vld.as_matrix(columns=features)\n",
        "Y_vld = XY_vld.as_matrix(columns=['y'])\n",
        "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
        "\n",
        "# 모델 정의 및 학습\n",
        "watch_list = [(dtrn,\"train\"),(dvld,'eval')]\n",
        "model = xgb.train(param,dtrn,num_boost_round=1000,evals=watch_list,early_stopping_rounds=20)\n",
        "\n",
        "# 모델 저장\n",
        "import pickle\n",
        "pickle.dump(model,open(\"model/xgb.baseline.pkl\",\"wb\"))\n",
        "base_ntree_limit = model.best_ntree_limit\n",
        "\n",
        "# 검증을 위한 MAP@7\n",
        "vld = trn[trn[\"fecha_dato\"] == vld_date]\n",
        "ncodpers_vld = vld.as_matrix(columns=['ncodpers'])\n",
        "\n",
        "for prod in prods:\n",
        "  pre = prod + \"_prev\"\n",
        "  padd = prod + \"_add\"\n",
        "  vld[padd] = vld[prod] - vld[prev]\n",
        "add_vld = vld.as_matrix(columns=[prod + \"_add\" for prod in prods])\n",
        "add_vld_list = [list() for i in range(len(ncodpers_vld))]\n",
        "\n",
        "count_vld = 0\n",
        "for ncodper in range(len(ncodpers_vld)):\n",
        "  for prod in range(len(prods)):\n",
        "    if add_vld[ncodper,prod] > 0:\n",
        "      add_vld_list[ncodper].append(prod)\n",
        "      count_vlt += 1\n",
        "\n",
        "X_vld = vld.as_matrix(columns=features)\n",
        "Y_vld = vld.as_matrix(columns=['y'])\n",
        "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
        "preds_vld = model.predict(dvld, ntree_limit=best_ntree_limit)\n",
        "\n",
        "preds_vld = preds_vld - vld.as_matrix(columns=[prod+\"_prev\" for prod in prods])\n",
        "\n",
        "result_vld = []\n",
        "for ncodper, pred in zip(ncodpers_vld, preds_vld):\n",
        "  y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
        "  y_prods = sorted(y_prods, key=lambda x: x[0], reverse=True)[:7]\n",
        "  result_vld.append([ip for y,p,ip in y_prods])\n",
        "\n",
        "print(mapk(add_vold_list,result_vld,7,0.0))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}